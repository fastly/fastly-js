# kafka

Kafka - JavaScript client for kafka
Fastly will upload log messages periodically to the server in the format specified in the Kafka object.
This SDK is automatically generated by the [OpenAPI Generator](https://openapi-generator.tech) project:

- API version: 1.0.0
- Package version: 1.0.0
- Build package: org.openapitools.codegen.languages.JavascriptClientCodegen

## Installation

### For [Node.js](https://nodejs.org/)

#### npm

To publish the library as a [npm](https://www.npmjs.com/), please follow the procedure in ["Publishing npm packages"](https://docs.npmjs.com/getting-started/publishing-npm-packages).

Then install it via:

```shell
npm install kafka --save
```

Finally, you need to build the module:

```shell
npm run build
```

##### Local development

To use the library locally without publishing to a remote npm registry, first install the dependencies by changing into the directory containing `package.json` (and this README). Let's call this `JAVASCRIPT_CLIENT_DIR`. Then run:

```shell
npm install
```

Next, [link](https://docs.npmjs.com/cli/link) it globally in npm with the following, also from `JAVASCRIPT_CLIENT_DIR`:

```shell
npm link
```

To use the link you just defined in your project, switch to the directory you want to use your kafka from, and run:

```shell
npm link /path/to/<JAVASCRIPT_CLIENT_DIR>
```

Finally, you need to build the module:

```shell
npm run build
```

#### git

If the library is hosted at a git repository, e.g.https://github.com/GIT_USER_ID/GIT_REPO_ID
then install it via:

```shell
    npm install GIT_USER_ID/GIT_REPO_ID --save
```

### For browser

The library also works in the browser environment via npm and [browserify](http://browserify.org/). After following
the above steps with Node.js and installing browserify with `npm install -g browserify`,
perform the following (assuming *main.js* is your entry file):

```shell
browserify main.js > bundle.js
```

Then include *bundle.js* in the HTML pages.

### Webpack Configuration

Using Webpack you may encounter the following error: "Module not found: Error:
Cannot resolve module", most certainly you should disable AMD loader. Add/merge
the following section to your webpack config:

```javascript
module: {
  rules: [
    {
      parser: {
        amd: false
      }
    }
  ]
}
```

## Getting Started

Please follow the [installation](#installation) instruction and execute the following JS code:

```javascript
var Kafka = require('kafka');

var defaultClient = Kafka.ApiClient.instance;
// Configure API key authorization: token_engineer
var token_engineer = defaultClient.authentications['token_engineer'];
token_engineer.apiKey = "YOUR API KEY"
// Uncomment the following line to set a prefix for the API key, e.g. "Token" (defaults to null)
//token_engineer.apiKeyPrefix['Fastly-Key'] = "Token"

var api = new Kafka.LoggingKafkaApi()
var serviceId = SU1Z0isxPaozGVKXdv0eY; // {String} 
var versionId = 1; // {Number} 
var opts = {
  'createdAt': "createdAt_example", // {String} Date and time in ISO 8601 format.
  'deletedAt': "deletedAt_example", // {String} Date and time in ISO 8601 format.
  'updatedAt': "updatedAt_example", // {String} Date and time in ISO 8601 format.
  'serviceId2': "serviceId_example", // {String} Alphanumeric string identifying the service.
  'version': 56, // {Number} Integer identifying a service version.
  'name': "name_example", // {String} The name for the real-time logging configuration.
  'placement': "placement_example", // {String} Where in the generated VCL the logging call should be placed. If not set, endpoints with `format_version` of 2 are placed in `vcl_log` and those with `format_version` of 1 are placed in `vcl_deliver`. 
  'formatVersion': 2, // {Number} The version of the custom logging format used for the configured endpoint. The logging call gets placed by default in `vcl_log` if `format_version` is set to `2` and in `vcl_deliver` if `format_version` is set to `1`.  
  'responseCondition': "responseCondition_example", // {String} The name of an existing condition in the configured endpoint, or leave blank to always execute.
  'format': "'%h %l %u %t \"%r\" %&gt;s %b'", // {String} A Fastly [log format string](https://docs.fastly.com/en/guides/custom-log-formats).
  'tlsCaCert': "'null'", // {String} A secure certificate to authenticate a server with. Must be in PEM format.
  'tlsClientCert': "'null'", // {String} The client certificate used to make authenticated requests. Must be in PEM format.
  'tlsClientKey': "'null'", // {String} The client private key used to make authenticated requests. Must be in PEM format.
  'tlsHostname': "'null'", // {String} The hostname to verify the server's certificate. This should be one of the Subject Alternative Name (SAN) fields for the certificate. Common Names (CN) are not supported.
  'topic': "topic_example", // {String} The Kafka topic to send logs to. Required.
  'brokers': "brokers_example", // {String} A comma-separated list of IP addresses or hostnames of Kafka brokers. Required.
  'compressionCodec': "compressionCodec_example", // {String} The codec used for compression of your logs.
  'requiredAcks': 1, // {Number} The number of acknowledgements a leader must receive before a write is considered successful.
  'requestMaxBytes': 0, // {Number} The maximum number of bytes sent in one request. Defaults `0` (no limit).
  'parseLogKeyvals': true, // {Boolean} Enables parsing of key=value tuples from the beginning of a logline, turning them into [record headers](https://cwiki.apache.org/confluence/display/KAFKA/KIP-82+-+Add+Record+Headers).
  'authMethod': "authMethod_example", // {String} SASL authentication method.
  'user': "user_example", // {String} SASL user.
  'password': "password_example", // {String} SASL password.
  'useTls': 0 // {Number} Whether to use TLS.
};
api.createLogKafka(serviceId, versionId, opts).then(function(data) {
  console.log('API called successfully. Returned data: ' + data);
}, function(error) {
  console.error(error);
});


```

## Documentation for API Endpoints

All URIs are relative to *https://api.fastly.com*

Class | Method | HTTP request | Description
------------ | ------------- | ------------- | -------------
*Kafka.LoggingKafkaApi* | [**createLogKafka**](docs/LoggingKafkaApi.md#createLogKafka) | **POST** /service/{service_id}/version/{version_id}/logging/kafka | Create a Kafka log endpoint
*Kafka.LoggingKafkaApi* | [**deleteLogKafka**](docs/LoggingKafkaApi.md#deleteLogKafka) | **DELETE** /service/{service_id}/version/{version_id}/logging/kafka/{logging_kafka_name} | Delete the Kafka log endpoint
*Kafka.LoggingKafkaApi* | [**getLogKafka**](docs/LoggingKafkaApi.md#getLogKafka) | **GET** /service/{service_id}/version/{version_id}/logging/kafka/{logging_kafka_name} | Get a Kafka log endpoint
*Kafka.LoggingKafkaApi* | [**listLogKafka**](docs/LoggingKafkaApi.md#listLogKafka) | **GET** /service/{service_id}/version/{version_id}/logging/kafka | List Kafka log endpoints
*Kafka.LoggingKafkaApi* | [**updateLogKafka**](docs/LoggingKafkaApi.md#updateLogKafka) | **PUT** /service/{service_id}/version/{version_id}/logging/kafka/{logging_kafka_name} | Update the Kafka log endpoint


## Documentation for Models

 - [Kafka.InlineObject](docs/InlineObject.md)
 - [Kafka.InlineResponse200](docs/InlineResponse200.md)
 - [Kafka.ModelLoggingKafka](docs/ModelLoggingKafka.md)


## Documentation for Authorization



### token_engineer


- **Type**: API key
- **API key parameter name**: Fastly-Key
- **Location**: HTTP header

